<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <title>Speechâ€‘toâ€‘Text Demo</title>
  <style>
    body { font-family: Arial; padding: 20px; max-width: 600px; margin: auto; }
    button {
      padding: 15px 30px; font-size: 18px;
      background: #4CAF50; color: #fff;
      border: none; border-radius: 6px; cursor: pointer;
      transition: background 0.2s;
    }
    button.recording { background: #f44336; }
    #text { margin-top: 20px; padding: 10px; border: 1px solid #ddd;
            min-height: 100px; background: #f9f9f9; white-space: pre-wrap; }
    #status { margin-top: 10px; font-style: italic; color: #666; }
  </style>
</head>
<body>
  <h2>Nháº¥n giá»¯ Ä‘á»ƒ nÃ³i</h2>
  <button id="btn">ðŸŽ¤ Giá»¯ Ä‘á»ƒ nÃ³i</button>
  <div id="status">Tráº¡ng thÃ¡i: sáºµn sÃ ng</div>
  <div id="text"></div>

  <script>
    const btn       = document.getElementById('btn');
    const statusDiv = document.getElementById('status');
    const textDiv   = document.getElementById('text');

    let recorder, audioChunks, stream;

    async function startRecording() {
      statusDiv.textContent = 'Tráº¡ng thÃ¡i: khá»Ÿi táº¡o microphone...';
      stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      // YÃªu cáº§u ghi WAV (náº¿u browser há»— trá»£)
      recorder = new MediaRecorder(stream, { mimeType: 'audio/wav' });
      audioChunks = [];
      recorder.ondataavailable = e => {
        if (e.data && e.data.size > 0) audioChunks.push(e.data);
      };
      recorder.start();
      statusDiv.textContent = 'Tráº¡ng thÃ¡i: Ä‘ang ghi Ã¢m...';
      btn.classList.add('recording');
    }

    function stopRecording() {
      return new Promise(resolve => {
        recorder.onstop = () => resolve();
        recorder.stop();
        btn.classList.remove('recording');
        statusDiv.textContent = 'Tráº¡ng thÃ¡i: Ä‘ang xá»­ lÃ½...';
        // stop all tracks
        stream.getTracks().forEach(t => t.stop());
      });
    }

    async function sendToServer() {
      const blob = new Blob(audioChunks, { type: 'audio/wav' });
      const arrayBuffer = await blob.arrayBuffer();
      const res = await fetch('/api/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'audio/wav' },
        body: arrayBuffer
      });
      const data = await res.json();
      if (data.status === 'success') {
        textDiv.textContent += data.text + '\n';
      } else if (data.status === 'no-speech') {
        textDiv.textContent += '[KhÃ´ng phÃ¡t hiá»‡n giá»ng nÃ³i]\n';
      } else {
        textDiv.textContent += `[Lá»—i: ${data.text}]\n`;
      }
      statusDiv.textContent = 'Tráº¡ng thÃ¡i: sáºµn sÃ ng';
    }

    btn.addEventListener('mousedown', () => {
      startRecording().catch(err => {
        console.error(err);
        statusDiv.textContent = 'Lá»—i khi truy cáº­p microphone';
      });
    });

    btn.addEventListener('mouseup', async () => {
      await stopRecording();
      await sendToServer();
    });

    // Touch support
    btn.addEventListener('touchstart', e => { e.preventDefault(); btn.dispatchEvent(new Event('mousedown')); });
    btn.addEventListener('touchend',   e => { e.preventDefault(); btn.dispatchEvent(new Event('mouseup')); });
  </script>
</body>
</html>
